{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5150774-edf4-4c82-9bd4-35b88db7778d",
   "metadata": {},
   "source": [
    "# Exploratory analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009978f-fa14-4786-84ec-6f1d2557b0e0",
   "metadata": {},
   "source": [
    "This notebook contains code for exploratory data analysis of data used in the project: Public attitudes and ethical guidelines in digital field experiments (digex)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57018cd9-e9c5-4ac7-8a93-078196055526",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff116ac0-7017-4a63-a0a7-cdae8019b4ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**We can roughly use the below bullet points taken from [2022-digex-study-design](https://docs.google.com/document/d/1nsaXEn04s9LTsjqrpbUpZlyQ3CAcuqkOwy1ZM0d-kKY/edit#) as section headings for this notebook to conduct the exploratory analysis**:\n",
    "\n",
    "- To address question 1, we will provide frequency tables or plots and descriptive statistics (M, SD, range) for the variables: awareness of the fact that academic researchers use social media data, awareness of the advantages of social media data that account for why academics collect them, awareness of social media data use, and awareness of social media interaction methods. \n",
    "\n",
    "- To address question 2, we will provide frequency tables or plots and descriptive statistics (M, SD, range) for each of the 4 vignette studies presented in section 2 of the survey for the variable: attitudes towards actual research studies. \n",
    "\n",
    "- To address question 3, we will provide frequency tables or plots for the variables attitudes towards study design factors and attitudes towards ethical principles. Moreover, we will also use a mixed-methods approach to analyze open-ended free-text responses (see below).\n",
    "\n",
    "- To further address questions 1-3, open-ended free-text inputs of both the open “other” options of selection items and the  open-ended free-text answers (i.e., what do you think it means for an academic study to receive \"ethical approval”, describe any concerns you might have, what additional information about the study or the researchers that would influence your level of concern, are there any other features of research that are important for determining your level of concern, are there any additional factors that you think should be considered) will be analyzed using a mixed-methods approach to detect common topics, sentiments, and themes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3083f-ec31-4300-8e86-cd50fe0b5498",
   "metadata": {},
   "source": [
    "## Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81b947d-7cc3-44ac-8f27-1743f89901a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib   # Change cwd\n",
    "import os \n",
    "\n",
    "path = pathlib.Path.cwd().parent\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8ead7-601f-4663-9449-4ed6294c2743",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0124c32d-cd56-461d-897e-5d230daae8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joypy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58243d-2dca-430c-bb74-6a09064297ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473d16f-0d4a-48cf-9fa1-c02fa8acabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = get_data_filepath(\n",
    "    file=config.PROCESSED_DATA_FILEPATH, \n",
    "    data_path=config.PROCESSED_DATA_DIR,\n",
    "    main=False\n",
    ") \n",
    "\n",
    "digex_df = pd.read_csv(processed_data_path, index_col=0)\n",
    "\n",
    "digex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5a2e1",
   "metadata": {},
   "source": [
    "The above didn't work for me (Jason), so using the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d179cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>finished</th>\n",
       "      <th>sm_use</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>ethnic_id</th>\n",
       "      <th>edu</th>\n",
       "      <th>politic_views</th>\n",
       "      <th>aware_sm_res</th>\n",
       "      <th>aware_sm_advan</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_pub_interst</th>\n",
       "      <th>rank_add_fac_1</th>\n",
       "      <th>rank_add_fac_1_pos</th>\n",
       "      <th>rank_add_fac_2</th>\n",
       "      <th>rank_add_fac_2_pos</th>\n",
       "      <th>rank_add_fac_3</th>\n",
       "      <th>rank_add_fac_3_pos</th>\n",
       "      <th>aware_sm_advan_score</th>\n",
       "      <th>aware_sm_interact_score</th>\n",
       "      <th>aware_sm_use_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>912.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian - Eastern</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Slightly liberal</td>\n",
       "      <td>Extremely aware</td>\n",
       "      <td>['… are large and can contain millions of data...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>720.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mixed race</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Neutral/ Neither conservative or liberal</td>\n",
       "      <td>Moderately aware</td>\n",
       "      <td>['… are large and can contain millions of data...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1874.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Pacific Islander</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Very liberal</td>\n",
       "      <td>Extremely aware</td>\n",
       "      <td>['… are large and can contain millions of data...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1264.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White / Caucasian</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Slightly conservative</td>\n",
       "      <td>Moderately aware</td>\n",
       "      <td>['… are large and can contain millions of data...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>556.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Native-American</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Very liberal</td>\n",
       "      <td>Extremely aware</td>\n",
       "      <td>['… often capture social relationships not fou...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration_sec  finished    sm_use   age gender_id          ethnic_id  \\\n",
       "1         912.0      True  Facebook  29.0      Male    Asian - Eastern   \n",
       "2         720.0      True   Twitter  33.0      Male         Mixed race   \n",
       "3        1874.0      True  Facebook  33.0    Female   Pacific Islander   \n",
       "4        1264.0      True  Facebook  73.0    Female  White / Caucasian   \n",
       "5         556.0      True   Twitter  27.0    Female    Native-American   \n",
       "\n",
       "                 edu                             politic_views  \\\n",
       "1         Highschool                          Slightly liberal   \n",
       "2         Highschool  Neutral/ Neither conservative or liberal   \n",
       "3  Bachelor's degree                              Very liberal   \n",
       "4         Highschool                     Slightly conservative   \n",
       "5         Highschool                              Very liberal   \n",
       "\n",
       "       aware_sm_res                                     aware_sm_advan  ...  \\\n",
       "1   Extremely aware  ['… are large and can contain millions of data...  ...   \n",
       "2  Moderately aware  ['… are large and can contain millions of data...  ...   \n",
       "3   Extremely aware  ['… are large and can contain millions of data...  ...   \n",
       "4  Moderately aware  ['… are large and can contain millions of data...  ...   \n",
       "5   Extremely aware  ['… often capture social relationships not fou...  ...   \n",
       "\n",
       "  rank_pub_interst rank_add_fac_1 rank_add_fac_1_pos rank_add_fac_2  \\\n",
       "1              1.0            NaN                NaN            NaN   \n",
       "2              4.0            NaN                NaN            NaN   \n",
       "3              1.0            NaN                NaN            NaN   \n",
       "4              1.0            NaN                8.0            NaN   \n",
       "5              7.0            NaN                NaN            NaN   \n",
       "\n",
       "  rank_add_fac_2_pos rank_add_fac_3 rank_add_fac_3_pos aware_sm_advan_score  \\\n",
       "1                NaN            NaN                NaN                    4   \n",
       "2                NaN            NaN                NaN                    1   \n",
       "3                NaN            NaN                NaN                    2   \n",
       "4                NaN            NaN                NaN                    1   \n",
       "5                NaN            NaN                NaN                    0   \n",
       "\n",
       "  aware_sm_interact_score aware_sm_use_score  \n",
       "1                       0                  9  \n",
       "2                       1                  9  \n",
       "3                       2                  5  \n",
       "4                       1                  6  \n",
       "5                       3                  9  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df = pd.read_csv('/Users/jasonburton/Documents/GitHub/article-digex-survey/data/processed/digex-survey-responses-processed.csv', index_col=0)\n",
    "\n",
    "digex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452d92e-a30d-4720-a355-31bdf5e6e28e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2aaa26-6394-4c0f-92d5-2ba35eee4289",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- https://aeturrell.github.io/coding-for-economists/data-exploratory-analysis.html#the-pandas-profiling-package\n",
    "- https://deepnote.com/@deepnote/Joyplot-Introduction-4666e1a3-3249-442e-9a94-2bbcc5cb1b1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d767843-097b-4c31-8327-9759f891ebc8",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2154f14-2b1b-4e7f-96c7-1c60d9a999da",
   "metadata": {},
   "source": [
    "**Variables to examine: 0-14**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f424173",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a19600-cefd-42a3-a409-91fb7aa49ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age: 41.66332665330661\n",
      "SD age: 13.635931661776896\n",
      "Minimum age: 18.0\n",
      "Maximum age: 78.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean age:\", digex_df['age'].mean())\n",
    "print(\"SD age:\", digex_df['age'].std())\n",
    "print(\"Minimum age:\", digex_df['age'].min())\n",
    "print(\"Maximum age:\", digex_df['age'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe4108",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2daa37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male                         0.565130\n",
       "Female                       0.414830\n",
       "Non-binary / third gender    0.016032\n",
       "Prefer not to say            0.004008\n",
       "Name: gender_id, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['gender_id'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d78bbf",
   "metadata": {},
   "source": [
    "#### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8c9d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White / Caucasian    0.795591\n",
       "African-American     0.064128\n",
       "Mixed race           0.040080\n",
       "Hispanic             0.038076\n",
       "Asian - Eastern      0.032064\n",
       "Asian - Indian       0.014028\n",
       "Native-American      0.006012\n",
       "Pacific Islander     0.002004\n",
       "Prefer not to say    0.002004\n",
       "Asian - Southeast    0.002004\n",
       "Carribean            0.002004\n",
       "Other                0.002004\n",
       "Name: ethnic_id, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['ethnic_id'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc05c8",
   "metadata": {},
   "source": [
    "#### Social media use\n",
    "\n",
    "*Note: there's an error on Qualtrics such that participants could only pick one option, instead of multiple. Since this is just a screener, we can simply note that all participants reported being a regular user of at least one of Facebook, Twitter, and/or Reddit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55befe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Facebook    258\n",
       "Reddit      133\n",
       "Twitter     108\n",
       "Name: sm_use, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['sm_use'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a2660",
   "metadata": {},
   "source": [
    "#### Political views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba57260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Very liberal                                150\n",
       "Slightly liberal                            126\n",
       "Slightly conservative                        96\n",
       "Neutral/ Neither conservative or liberal     89\n",
       "Very conservative                            35\n",
       "Prefer not to say                             3\n",
       "Name: politic_views, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['politic_views'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f51306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5531062124248497"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion liberal\n",
    "( (digex_df['politic_views'].value_counts()['Very liberal']) + \n",
    "(digex_df['politic_views'].value_counts()['Slightly liberal']) )/len(digex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96f2f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2625250501002004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion conservative\n",
    "( (digex_df['politic_views'].value_counts()['Very conservative']) + \n",
    "(digex_df['politic_views'].value_counts()['Slightly conservative']) )/len(digex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b83b68-9a10-4dd8-ba06-267f793f2980",
   "metadata": {},
   "source": [
    "### Prior awareness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05d969-36ab-495d-9f49-a5f94a8abe13",
   "metadata": {},
   "source": [
    "**Variables to examine: 8-15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296bfce-ae1a-4834-b423-ee2cc2cf5d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7dfbeed-33b9-43db-9dd0-73a38b9824d4",
   "metadata": {},
   "source": [
    "### Study descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8ac2f-a24b-450c-952b-30ee1c95f625",
   "metadata": {},
   "source": [
    "**Variables to examine: 16-27**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab99530-bf28-43e2-9364-58b763c091f6",
   "metadata": {},
   "source": [
    "#### Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf7c828-3723-4b47-9630-b6a84e576d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completely acceptable      0.314629\n",
       "Somewhat acceptable        0.288577\n",
       "Somewhat unacceptable      0.162325\n",
       "Neutral                    0.124248\n",
       "Completely unacceptable    0.110220\n",
       "Name: study_1_ethic_acc, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['study_1_ethic_acc'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d556f4-5174-440b-bd1a-31b39d6ce7e8",
   "metadata": {},
   "source": [
    "#### Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e8e5ca-6dc6-4c10-a59d-08b518df0d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Somewhat acceptable        0.266533\n",
       "Completely acceptable      0.232465\n",
       "Somewhat unacceptable      0.222445\n",
       "Neutral                    0.164329\n",
       "Completely unacceptable    0.114228\n",
       "Name: study_2_ethic_acc, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['study_2_ethic_acc'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6125e8-4a4f-4216-82fe-e3979a564a5f",
   "metadata": {},
   "source": [
    "#### Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffb67b7-e050-40ca-b88f-b08702fdfe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completely acceptable      0.498998\n",
       "Somewhat acceptable        0.268537\n",
       "Neutral                    0.112224\n",
       "Somewhat unacceptable      0.078156\n",
       "Completely unacceptable    0.042084\n",
       "Name: study_3_ethic_acc, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['study_3_ethic_acc'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d4157-3768-4b0c-8aa6-808d44a1c107",
   "metadata": {},
   "source": [
    "#### Study 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d02c135-f3c7-4e93-8d22-0a406548e9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Somewhat acceptable        0.242485\n",
       "Completely acceptable      0.230461\n",
       "Somewhat unacceptable      0.220441\n",
       "Neutral                    0.176353\n",
       "Completely unacceptable    0.130261\n",
       "Name: study_4_ethic_acc, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digex_df['study_4_ethic_acc'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2671f",
   "metadata": {},
   "source": [
    "#### Study comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b9173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_1_ethic_acc_num = digex_df['study_1_ethic_acc'].map({'Completely unacceptable': -2, \n",
    "                                                           'Somewhat unacceptable': -1, \n",
    "                                                           'Neutral': 0, \n",
    "                                                           'Somewhat acceptable': 1, \n",
    "                                                           'Completely acceptable': 2})\n",
    "study_2_ethic_acc_num = digex_df['study_2_ethic_acc'].map({'Completely unacceptable': -2, \n",
    "                                                           'Somewhat unacceptable': -1, \n",
    "                                                           'Neutral': 0, \n",
    "                                                           'Somewhat acceptable': 1, \n",
    "                                                           'Completely acceptable': 2})\n",
    "study_3_ethic_acc_num = digex_df['study_3_ethic_acc'].map({'Completely unacceptable': -2, \n",
    "                                                           'Somewhat unacceptable': -1, \n",
    "                                                           'Neutral': 0, \n",
    "                                                           'Somewhat acceptable': 1, \n",
    "                                                           'Completely acceptable': 2})\n",
    "study_4_ethic_acc_num = digex_df['study_4_ethic_acc'].map({'Completely unacceptable': -2, \n",
    "                                                           'Somewhat unacceptable': -1, \n",
    "                                                           'Neutral': 0, \n",
    "                                                           'Somewhat acceptable': 1, \n",
    "                                                           'Completely acceptable': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39de1541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Study 1 acceptance: 0.5350701402805611\n",
      "Mean Study 2 acceptance: 0.280561122244489\n",
      "Mean Study 3 acceptance: 1.1042084168336674\n",
      "Mean Study 4 acceptance: 0.22244488977955912\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Study 1 acceptance:\", study_1_ethic_acc_num.mean())\n",
    "print(\"Mean Study 2 acceptance:\", study_2_ethic_acc_num.mean())\n",
    "print(\"Mean Study 3 acceptance:\", study_3_ethic_acc_num.mean())\n",
    "print(\"Mean Study 4 acceptance:\", study_4_ethic_acc_num.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ac3c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = [1,2,3,4]\n",
    "y = [study_1_ethic_acc_num.mean(), \n",
    "     study_2_ethic_acc_num.mean(),\n",
    "     study_3_ethic_acc_num.mean(),\n",
    "     study_4_ethic_acc_num.mean()]\n",
    "yerr = [study_1_ethic_acc_num.std(), \n",
    "     study_2_ethic_acc_num.std(),\n",
    "     study_3_ethic_acc_num.std(),\n",
    "     study_4_ethic_acc_num.std()] \n",
    "\n",
    "ax.errorbar(x, y, yerr, fmt='o', linewidth=2, capsize=6)\n",
    "\n",
    "ax.set(xlim=(0, 5), xticks=np.arange(1, 5),\n",
    "       ylim=(-2, 3), yticks=np.arange(-2, 3))\n",
    "\n",
    "plt.xlabel('Study Number') \n",
    "plt.ylabel('Ethical Acceptance ±1 SD') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e046a-efd4-477d-b322-766b0e39c432",
   "metadata": {},
   "source": [
    "### Study design features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45cd8a-8ba9-4b28-8318-2fe6b86be47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebdf076d",
   "metadata": {},
   "source": [
    "### Ethical priorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef20e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = digex_df[['rank_sci_repro', 'rank_resp', 'rank_just', 'rank_anony', 'rank_harms', 'rank_balance', 'rank_pub_interst']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2582960",
   "metadata": {},
   "source": [
    "Ranks by means (lower value = higher priority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f3b150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank_harms          2.697395\n",
       "rank_anony          3.054108\n",
       "rank_resp           3.527054\n",
       "rank_pub_interst    3.573146\n",
       "rank_just           4.651303\n",
       "rank_balance        4.975952\n",
       "rank_sci_repro      5.521042\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_means = ranks.mean()\n",
    "ranks_means.sort_values(inplace=True, ascending=True)\n",
    "ranks_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82696cd",
   "metadata": {},
   "source": [
    "Ranks by Borda count (higher value = higher priority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b77dfdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank_harms          2147.0\n",
       "rank_anony          1969.0\n",
       "rank_resp           1733.0\n",
       "rank_pub_interst    1710.0\n",
       "rank_just           1172.0\n",
       "rank_balance        1010.0\n",
       "rank_sci_repro       738.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_borda = ranks.replace({1:6, 2:5, 3:4, 4:3, 5:2, 6:1, 7:0})    \n",
    "ranks_borda = ranks_borda.sum()\n",
    "ranks_borda.sort_values(inplace=True, ascending=False)\n",
    "ranks_borda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
